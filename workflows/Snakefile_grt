import yaml
import pandas as pd 
import numpy as np
import os
configfile: "config/config_grts.yaml"

def cartesian_product(*arrays):
    meshgrids = np.meshgrid(*arrays,indexing='ij')
    cart_prod = np.stack(meshgrids,axis=-1)
    cart_prod = cart_prod.reshape(-1,len(arrays))
    return cart_prod

def n_targets(params_dict):
    '''Calculates the number of targets needed and return them as a range
    '''
    n_targets = 1
    for inputs in params_dict.values():
        n_targets = n_targets * eval(inputs).shape[0]

    return range(n_targets)

graphs_dir = config['graphs_dir']
methods = config['methods'].keys()


rule all:
    input:
        # "data/networks/giant_hamsterster/reductions/coarsening/test/graph_00/drawing.png",
        # "data/networks/giant_hamsterster/reductions/coarsening/test/graph_00/metrics.yaml",
        # "data/networks/giant_hamsterster/reductions/coarsening/test/graph_00/distribution_degree.yaml",
        # "data/networks/giant_hamsterster/reductions/coarsening/test/graph_00/distribution_distance.yaml",
        # "data/networks/giant_hamsterster/reductions/coarsening/test/graph_00/simulations/sir/test/qois.csv",
        "results/giant_hamsterster/coarsening/test/metrics.csv",
        "results/giant_hamsterster/coarsening/test/distribution_degree.csv",
        "results/giant_hamsterster/coarsening/test/distribution_distance.csv"

rule graph_reduce:
    input:
        "{path}/adjacency.npz",
        "{path}/reductions/{method}/{target_id}/parameters.yaml"
    output:
        "{path}/reductions/{method}/{target_id}/{graph_id}/adjacency.npz"
    script:
        "scripts/graph_reduce_{wildcards.method}.py"

rule graph_metrics:
    input:
        "{path}/adjacency.npz"
    output:
        "{path}/metrics.yaml"
    script:
        "scripts/graph_characterize.py"

rule graph_distribution:
    input:
        "{path}/adjacency.npz"
    output:
        "{path}/distribution_{quantity}.npy"
    script:
        "scripts/graph_distribution.py"

rule graph_distribution_metrics:
    input:
        "{path}/distribution_{quantity}.npy"
    output:
        "{path}/distribution_{quantity}.yaml"
    script:
        "scripts/graph_distribution_metrics.py"

rule graph_draw:
    input:
        "{path}/adjacency.npz"
    output:
        "{path}/drawing.png"
    script:
        "scripts/graph_draw.py"

rule simulate:
    input:
        "{path}/adjacency.npz",
        "{path}/simulations/{model}/{sim_id}/parameters.yaml"
    output:
        "{path}/simulations/{model}/{sim_id}/trajectories.npy"
    params:
        n_trials=config['n_trials']
    script:
        "scripts/simulation_{wildcards.model}_run.py"

rule qois_sir:
    input:
        "{path}/sir/{sim_id}/trajectories.npy"
    output:
        "{path}/sir/{sim_id}/qois.csv"
    script:
        "scripts/simulation_sir_qois.py"

rule test_targets_seed:
    output:
        "{path}/reductions/{method}/{test_id}.csv"
    params:
        config=lambda w:config['methods'][w.method]['parameters']
    run:
        # Calculate cartesian product of input parameters
        parameters = cartesian_product(*[eval(param) for param in params.config.values()])

        # Create DataFrame
        parameters = pd.DataFrame(parameters,columns=params.config.keys())
        parameters.to_csv(output[0],index=False)

rule test_targets_scatter:
    input:
        "{path}/reductions/{method}/{test_id}.csv"
    output:
        "{path}/reductions/{method}/{test_id}_{target_id}/parameters.yaml"
    run:
        # Load DataFrame
        parameters = pd.read_csv(input[0])

        # Convert parameters to dictionary
        idx = int(wildcards.target_id)
        parameters = parameters.iloc[idx].to_dict()

        # Write parameters
        with open(output[0],'w') as file:
            yaml.dump(parameters,file,default_flow_style=False)


# TEST 
file_path = lambda w, file: [f"{graphs_dir}/{w.graph_name}/reductions/{w.method}/{w.test_id}_{target_id}/graph_{graph_id}/{file}" for \
            target_id in n_targets(config['methods'][w.method]['parameters']) for \
            graph_id in range(config['methods'][w.method]['n_graphs'])]

# rule test_method_all:
#     input:
#         drawings=lambda w: file_path(w,"drawing.png"),
#         metrics=lambda w: file_path(w,"metrics.yaml"),
#         dists_degree=lambda w: file_path(w,"distribution_degree.yaml"),
#         dists_distance=lambda w: file_path(w,"distribution_distance.yaml")
#     output:
#         "results/{graph_name}/{method}/{test_id}/metrics.csv",
#         "results/{graph_name}/{method}/{test_id}/distribution_degree.yaml",
#         "results/{graph_name}/
#     run:

rule graph_metrics_aggregate:
    input:
        files=lambda w: file_path(w,f"{w.path}.yaml")
    output: 
        "results/{graph_name}/{method}/{test_id}/{path}.csv"
    run:
        dicts = []
        # Load every file into a dictionary
        for file_name in input.files:
            with open(file_name,'r') as file:
                dicts.append(yaml.safe_load(file))

        # Create dataframe
        df = pd.DataFrame(dicts)
        df['names'] = input.files 
        df.set_index('names',inplace=True)
        df.rename(lambda idx: os.path.dirname(idx),inplace=True)

        # Save df
        df.to_csv(output[0])

