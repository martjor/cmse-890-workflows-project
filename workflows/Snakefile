import numpy as np
import pandas as pd
import yaml
import shutil
from scripts.utils.io import load_dict, save_dict
import hashlib
import matplotlib.pyplot as plt

configfile: "config/config.yaml"
settings=["warmup", "sir", "layout","n_miniatures"]
networks=[network for network in config['miniaturization'].keys() if network not in settings]
synthetic_n_nodes = [256, 576, 2304]

rule all:
    input:
        # f"results/{graph}/drawings/giant.png",
        # expand("results/{graph}/drawings/{method}/{miniature}.png",
        #     graph=graph,
        #     method=methods,
        #     miniature=miniatures),
        # expand("results/{graph}/sir/{which}_{method}.png",
        #     graph=graph,
        #     which=["trajectories","qois"],
        #     method=methods),
        # expand("results/{graph}/metrics/{which}_{method}.png",
        #     graph=graph,
        #     which=["spectral","reduction","networks"],
        #     method=methods),
        # expand("results/{graph}/miniaturization/trajectories_{which}_{miniature}.png",
        #     graph=graph,
        #     which=["plane","error"],
        #     miniature=miniatures)
        expand(
            "results/miniaturization/{network}/{file}.png",
            network=networks,
            file=["networks","sir_curves"]
        ),
        expand(
            "data/networks/synthetic/{model}_{n_nodes}/graph_metrics.yaml",
            model=['er','ws','ba'],
            n_nodes=synthetic_n_nodes
        )

rule min_params:
    '''Calculates the optimal miniaturization parameters of a graph
    
    Input:
        - YAML file containing the metrics of the graphs to miniaturize

    Output:
        - YAML file containg the optimal weights and inverse temperature to miniaturize
          the graph to the specified size
    '''
    input:
        "data/networks/{network}/graph_metrics.yaml"
    output:
        "data/miniaturization/{network}/params_{n_nodes}_[{metrics}].yaml"
    resources:
        runtime=400,
        mem_mb=2000
    log:
        "logs/min/{network}/params_{n_nodes}_[{metrics}].log"
    params:
        n_nodes=lambda w: int(w.n_nodes), 
        n_steps=config['miniaturization']['warmup']['n_steps'],
        n_trials=config['miniaturization']['warmup']['n_trials'],
        targets=lambda w: w.metrics.split(',')

    script:
        "scripts/reduction/miniaturize_params.py"

rule reduction:
    '''Miniaturizes a graph using the parallel tempering algorithm

    Input:
        - YAML file containing the of the graph
        - YAML file containing the miniaturization weights and inverse temperature
    
    Output:
        - Scipy Sparse Array representing the adjacency matrix of the miniature
        - Directory of parquet files containing the individual trajectories of each
          replica of the parallel tempering algorithm
    '''
    input:
        "data/networks/{network}/graph_metrics.yaml",
        "data/miniaturization/{network}/params_{n_nodes}_[{metrics}].yaml"
    output:
        "data/miniaturization/{network}/min_{n_nodes}_[{metrics}]_{idx}/graph_adjacency.npz",
        directory("data/miniaturization/{network}/min_{n_nodes}_[{metrics}]_{idx}/trajectories/")
    params:
        n_nodes=lambda w: int(w.n_nodes),
        n_steps=lambda w: config['miniaturization'][w.network][f"min_{w.n_nodes}"]['n_exchanges'],
        n_substeps=lambda w: config['miniaturization'][w.network][f"min_{w.n_nodes}"]['n_steps'],
        targets=lambda w: w.metrics.split(',')
    resources:
        runtime=1440,
        mem_mb=6000,
        tasks=6,
        mpi="mpiexec"
    conda:
        "envs/miniaturize.yaml"
    log:
        "logs/min/{network}/reduct_{n_nodes}_[{metrics}]_{idx}.log"
    shell:
        "{resources.mpi} -n {resources.tasks} python -m scripts.reduction.miniaturize"
        " {input[0]} {input[1]} {output[0]} {output[1]} {params.n_nodes} {params.targets}"
        " --n_steps {params.n_steps}"
        " --n_substeps {params.n_substeps}"
        " --log-file {log[0]}"

rule random_graphs:
    '''Creates Random ER graphs with the same diffusion properties as the target graph
    '''
    input:
        "data/networks/{network}/graph_metrics.yaml"
    output:
        "data/miniaturization/{network}/random_{n_nodes}_{idx}/graph_adjacency.npz"
    params:
        n_nodes=lambda w: int(w.n_nodes)
    script:
        "scripts/reduction/random_graphs.py"

rule graphs_synthetic:
    '''Creates synthetic graphs
    '''
    output:
        expand("data/networks/synthetic/{model}_{n_nodes}/graph_adjacency.npz",model=['er','ws','ba'],n_nodes=synthetic_n_nodes)
    script:
        "scripts/synthetic/generate.py"

# rule coarsen:
#     '''Coarsens a graph dataset

#     Input:
#         - Scipy Sparse Array containing the adjacency matrix of the graph to coarsen
    
#     Output:
#         - Scipy Sparse Array containing the adjacency matrix of the reduced graph
#     '''
#     input:
#         "data/networks/{graph}/giant/graph_adjacency.npz",
#     output:
#         "data/networks/{graph}/giant/coarsening/{miniature}/graph_adjacency.npz",
#     log:
#         "logs/{graph}/coarsening/{miniature}/reduction.log"
#     message:
#         "Coarsening graph '{wildcards.graph}' ({wildcards.miniature})..."
#     params:
#         alpha=lambda w:config['miniatures'][w.miniature]['alpha']
#     resources:
#         runtime=60,
#         mem_mb=2000
#     script:
#         "scripts/reduction/coarsen.py"

# rule sparsify:
#     '''Sparsifies a graph dataset

#     Input:
#         - Scipy Sparse Array with the adjacency matrix the graph to sparsify.
#     Output:
#         - Scipy Sparse Array with the adjacency matrix of the sparsified graph.
#     '''
#     input:
#         "data/networks/{graph}/giant/graph_adjacency.npz",
#         "data/networks/{graph}/giant/miniaturization/{miniature}/graph_metrics.yaml"
#     output:
#         "data/networks/{graph}/giant/sparsification/{miniature}/graph_adjacency.npz"
#     log:
#         "logs/{graph}/sparsification/{miniature}/reduction.log"
#     message:
#         "Sparsifying graph '{wildcards.graph}' ({wildcards.miniature})..."
#     resources:
#         runtime=15,
#         mem_mb=6000
#     script:
#         "scripts/reduction/sparsify.py"

rule metrics:
    '''Characterizes a graph by calculating its relevant metrics

    Input:
        - Scipy Sparse Array containing the adjacency matrix of the graph
    
    Output:
        - YAML file containing the network metrics of the graph
    '''
    input:
        "{path}/graph_adjacency.npz"
    output:
        "{path}/graph_metrics.yaml"
    script:
        "scripts/graph_characterize.py"

# rule distribution:
#     '''Calculates the distribution over some node property

#     The degree distribution of the pairwise-distance distribution of graph
#     nodes is calculated. 

#     Input:
#         - Scipy Sparse Array containing the adjacency matrix of the graph

#     Output:
#         - 2-D Numpy Array representing the PDF of the specified property.
#           The first column contains that the prroperty takes. The second
#           column are the frequencies for each value.
#     '''
#     input:
#         "{path}/graph_adjacency.npz"
#     output:
#         "{path}/distribution_{quantity}.npy"
#     script:
#         "scripts/graph_distribution.py"

# rule distribution_metrics:
#     '''Calculates metrics from the specified distribution. 

#     Calculates relevant measures of central tendency as well as some 
#     low order moments of the distribution.

#     Input:
#         - Numpy Array containing the distribution.

#     Output:
#         - YAML file containing the requested metrics.
#     '''
#     input:
#         "{path}/distribution_{quantity}.npy"
#     output:
#         "{path}/distribution_{quantity}.yaml"
#     script:
#         "scripts/graph_distribution_metrics.py"

rule sir:
    '''Simulates the diffusion model on the graph.

    For the SIR model, the trajectories returned by the rule are the 
    normalized populations for each compartment at every iteration.

    Input:
        - Scipy Sparse Array containing the adjacency matrix of the graph.

    Output:
        - Numpy Array containing the relevant trajectories of the model.
    '''
    input:
        "{path}/graph_adjacency.npz",
    output:
        "{path}/sir_trajectories.npy"
    params:
        n_steps=config['miniaturization']['sir']['n_steps'],
        n_trials=config['miniaturization']['sir']['n_trials'],
        tau=config['miniaturization']['sir']['tau'],
        gamma=config['miniaturization']['sir']['gamma']
    resources:
        runtime=60,
        mem_mb=1000,
        cpus_per_task=1,
    script:
        "scripts/sir/simulate.py"

# rule draw_miniature:
#     '''Generates visualization for PT miniaturization.
#     '''
#     input:
#         "data/networks/{graph}/giant/graph_metrics.yaml",
#         "data/networks/{graph}/giant/miniaturization/{miniature}/graph_metrics.yaml",
#         "data/networks/{graph}/giant/miniaturization/{miniature}/trajectories"
#     output:
#         "results/{graph}/miniaturization/trajectories_plane_{miniature}.png",
#         "results/{graph}/miniaturization/trajectories_error_{miniature}.png"
#     notebook:
#         "scripts/draw/miniaturization_trajectories.py.ipynb"

# rule draw_metrics:
#     '''Plots the evolution of graph metrics.
#     '''
#     input:
#         "data/networks/{graph}/giant/graph_metrics.yaml",
#         expand("data/networks/{{graph}}/giant/{{method}}/{miniature}/graph_metrics.yaml",miniature=miniatures)
#     params:
#         alpha=lambda w: {miniature: config['miniatures'][miniature]['alpha'] for miniature in miniatures}
#     output:
#         "results/{graph}/metrics/reduction_{method}.png",
#         "results/{graph}/metrics/networks_{method}.png",
#         "results/{graph}/metrics/spectral_{method}.png"
#     notebook:
#         "scripts/draw/metrics.py.ipynb"

# def draw_sir_input(wildcards):
#     # Define extension
#     if wildcards.type == "trajectories":
#         extension = "npy"
#     elif wildcards.type == "qois":
#         extension = "yaml"

#     # Construct list of input files
#     files = []
#     files.append(f"data/networks/{wildcards.graph}/giant/sir_{wildcards.type}.{extension}")
#     for miniature in miniatures:
#         files.append(f"data/networks/{wildcards.graph}/giant/{wildcards.method}/{miniature}/sir_{wildcards.type}.{extension}")

#     return files

# rule draw_sir:
#     '''Plots the trajectories of the SIR model.

#     Input:
#         - Numpy Array of SIR trajectories.

#     Output:
#         - PNG file with an SIR plot.
#     '''
#     input:
#         draw_sir_input
#     params:
#         alpha=lambda w: {miniature: config['miniatures'][miniature]['alpha'] for miniature in miniatures}
#     output:
#         "results/{graph}/sir/{type}_{method}.png"
#     notebook:
#         "scripts/draw/sir_{wildcards.type}.py.ipynb"

rule sir_qois:
    '''Calculates the Quantities of Interest of the SIR model.

    The QOIs include total epidemic size, peak of number of infected
    people, and time-to-peak.

    Input:
        - Numpy array of SIR trajectories.

    Output:
        - YAML file with the QOIs of the SIR model.
    '''
    input:
        "{path}/sir_trajectories.npy"
    output:
        "{path}/sir_qois.yaml"
    script:
        "scripts/sir/qois.py"

rule sir_curves:
    '''Generate visualizations for the SIR model using the graph miniatures
    '''
    input:
        original="data/networks/{network}/sir_trajectories.npy",
        miniatures=lambda w:[
            f"data/miniaturization/{w.network}/{miniature}_[{','.join(config['miniaturization'][w.network]['targets'])}]_{idx}/sir_trajectories.npy" \
            for idx in range(config['miniaturization']['n_miniatures']) \
            for miniature in config['miniaturization'][w.network].keys() if "min_" in miniature
        ],
        ers=lambda w:[
            f"data/miniaturization/{w.network}/random_{miniature.split('_')[1]}_{idx}/sir_trajectories.npy" \
            for idx in range(config['miniaturization']['n_miniatures']) \
            for miniature in config['miniaturization'][w.network].keys() if "min_" in miniature
        ]
    output:
        "results/miniaturization/{network}/sir_curves.png"
    script:
        "scripts/sir/curves.py"

rule draw_miniaturization:
    '''Draws the original graph as well as all its miniatures
    '''
    input:
        original=expand("data/networks/{{network}}/{file}", file=["graph_adjacency.npz", "graph_metrics.yaml", "graph_layout.npy"]),
        miniatures= lambda w: [
            f"data/miniaturization/{w.network}/{miniature}_[{','.join(config['miniaturization'][w.network]['targets'])}]_{idx}/{file}"
            for miniature in config['miniaturization'][w.network].keys() if "min_" in miniature
            for idx in range(config['miniaturization']['n_miniatures']) 
            for file in ["graph_adjacency.npz", "graph_metrics.yaml", "graph_layout.npy"] 
        ]
        # miniatures=lambda w:[
        #     [

        #     ]
        #     f"data/miniaturization/{w.network}/{miniature}_[{','.join(config['miniaturization'][w.network]['targets'])}]_{idx}/graph_layout.npy" \
        #     for idx in range(config['miniaturization']['n_miniatures']) \
        #     for miniature in config['miniaturization'][w.network].keys() if "min_" in miniature
        # ]
    output:
        "results/miniaturization/{network}/networks.png"
    params:
        n_graphs=config['miniaturization']['n_miniatures'],
        targets=lambda w:config['miniaturization'][w.network]['targets']
    script:
        "scripts/draw/networks.py"


rule layout:
    '''Calculates the graph layout to enable visualization

    Utilizes the ForceAtlas2 algorithm to calculate the layout of the graph dataset.

    Input:
        - Scipy Sparse Array containing the adjacency matrix of the graph.

    Output:
        - Numpy array containing the positions specifying the graph layout
    '''
    input:
        "{path}/graph_adjacency.npz"
    output:
        "{path}/graph_layout.npy"
    params:
        max_iter=config['miniaturization']['layout']['max_iter']
    script:
        "scripts/draw/graph_layout.py"

# rule draw_reduction:
#     input:
#         "data/networks/{graph}/giant/{method}/{miniature}/graph_adjacency.npz",
#         "data/networks/{graph}/giant/{method}/{miniature}/graph_layout.npy"
#     output:
#         "results/{graph}/drawings/{method}/{miniature}.png"
#     wildcard_constraints:
#         method="coarsening|miniaturization"
#     message:
#         "Drawing graph {wildcards.miniature} for {wildcards.method}..."
#     script:
#         "scripts/draw/graph.py"

# rule draw_sparsification:
#     '''Creates a visualization of the graph dataset.

#     Takes a previously generated graph layout and draws a graph on top of it.

#     Input:
#         - Numpy Array containing the graph layout

#     Output:
#         - PNG file with a visualization of the graph dataset
#     '''
#     input:
#         "data/networks/{graph}/giant/sparsification/{miniature}/graph_adjacency.npz",
#         "data/networks/{graph}/giant/graph_layout.npy"
#     output:
#         "results/{graph}/drawings/sparsification/{miniature}.png"
#     message:
#         "Drawing graph {wildcards.miniature} for sparsification..."
#     script:
#         "scripts/draw/graph.py"

# rule draw_graph_original:
#     input:
#         "data/networks/{graph}/giant/graph_adjacency.npz",
#         "data/networks/{graph}/giant/graph_layout.npy"
#     output:
#         "results/{graph}/drawings/giant.png"
#     message:
#         "Drawing graph {wildcards.graph}..."
#     script:
#         "scripts/draw/graph.py"

