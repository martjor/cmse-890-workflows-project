import numpy as np
import pandas as pd
import yaml
import shutil

configfile: "config/config.yaml"

methods = ["coarsening"]
miniatures = list(config['miniatures'].keys())

rule all:
    input:
        expand("data/networks/hamsterster/giant/{method}/{miniature_id}/graph_adjacency.npz",
            method=methods,
            miniature_id=miniatures)
        
rule miniaturization_params:
    '''Calculates the optimal miniaturization parameters of a graph
    
    Input:
        - YAML file containing the metrics of the graphs to miniaturize

    Output:
        - YAML file containg the optimal weights and inverse temperature to miniaturize
          the graph to the specified size
    '''
    input:
        "data/networks/{graph}/metrics.yaml"
    output:
        "data/networks/{graph}/miniaturization/parameters_{id}.yaml"
    resources:
        runtime=400,
        mem_mb=2000
    log:
        "logs/{graph}/reduction/miniaturization/parameters_{id}/parameters.log"
    params:
        params=lambda w:samples['miniaturization'].loc[int(w.id)],
        n_trials=30,
        n_steps=100
    script:
        "scripts/miniaturization_params.py"

rule miniaturization:
    '''Miniaturizes a graph using the parallel tempering algorithm

    Input:
        - YAML file containing the of the graph
        - YAML file containing the miniaturization weights and inverse temperature
    
    Output:
        - Scipy Sparse Array representing the adjacency matrix of the miniature
        - Directory of parquet files containing the individual trajectories of each
          replica of the parallel tempering algorithm
    '''
    input:
        "data/networks/{graph}/metrics.yaml",
        lambda w: f"data/networks/{w.graph}/miniaturization/parameters_{int(w.idx) // config['methods']['miniaturization']['n_graphs']}.yaml"
    output:
        "data/networks/{graph}/miniaturization/graph_{idx}/graph_adjacency.npz",
        directory("data/networks/{graph}/miniaturization/graph_{idx}/trajectories")
    params:
        params=lambda w:samples['miniaturization'].loc[int(w.idx)]
    resources:
        runtime=1440,
        mem_mb=2000,
        tasks=6,
        mpi="mpiexec"
    conda:
        "envs/miniaturize.yaml"
    log:
        "logs/{graph}/reduction/miniaturization/graph_{idx}.log"
    shell:
        "{resources.mpi} -n {resources.tasks} scripts/miniaturize.py"
        " {input[0]} {input[1]} {output[0]} {output[1]} {params.params['alpha']}"
        " --n_changes {params.params['n_changes']}"
        " --n_steps {params.params['n_steps']}"
        " --n_substeps {params.params['n_sub_steps']}"
        " --log-file {log[0]}"

rule coarsen:
    '''Coarsens a graph dataset

    Input:
        - Scipy Sparse Array containing the adjacency matrix of the graph to coarsen
    
    Output:
        - Scipy Sparse Array containing the adjacency matrix of the reduced graph
    '''
    input:
        "data/networks/{graph}/graph_adjacency.npz",
    output:
        "data/networks/{graph}/coarsening/{miniature}/graph_adjacency.npz",
    log:
        "logs/{graph}/reduction/coarsening/{miniature}.log"
    message:
        "Coarsening graph '{wildcards.graph}' ({wildcards.miniature})..."
    params:
        alpha=lambda w:config['miniatures'][w.miniature]['alpha']
    resources:
        runtime=60,
        mem_mb=2000
    script:
        "scripts/reduction/coarsen.py"

rule characterize:
    '''Characterizes a graph by calculating its relevant metrics

    Input:
        - Scipy Sparse Array containing the adjacency matrix of the graph
    
    Output:
        - YAML file containing the network metrics of the graph
    '''
    input:
        "{path}/graph_adjacency.npz"
    output:
        "{path}/graph_metrics.yaml"
    script:
        "scripts/graph_characterize.py"

rule distribution:
    '''Calculates the distribution over some node property

    The degree distribution of the pairwise-distance distribution of graph
    nodes is calculated. 

    Input:
        - Scipy Sparse Array containing the adjacency matrix of the graph

    Output:
        - 2-D Numpy Array representing the PDF of the specified property.
          The first column contains that the prroperty takes. The second
          column are the frequencies for each value.
    '''
    input:
        "{path}/graph_adjacency.npz"
    output:
        "{path}/distribution_{quantity}.npy"
    script:
        "scripts/graph_distribution.py"

rule distribution_metrics:
    '''Calculates metrics from the specified distribution. 

    Calculates relevant measures of central tendency as well as some 
    low order moments of the distribution.

    Input:
        - Numpy Array containing the distribution.

    Output:
        - YAML file containing the requested metrics.
    '''
    input:
        "{path}/distribution_{quantity}.npy"
    output:
        "{path}/distribution_{quantity}.yaml"
    script:
        "scripts/graph_distribution_metrics.py"

rule simulate:
    '''Simulates the diffusion model on the graph.

    For the SIR model, the trajectories returned by the rule are the 
    normalized populations for each compartment at every iteration.

    Input:
        - Scipy Sparse Array containing the adjacency matrix of the graph.

    Output:
        - Numpy Array containing the relevant trajectories of the model.
    '''
    input:
        "{path}/graph_adjacency.npz",
    output:
        "{path}/trajectories_{model}.npy"
    params:
        config=lambda w:config['models'][w.model]
    resources:
        runtime=60,
        mem_mb=1000,
        cpus_per_task=1,
    script:
        "scripts/simulation_{wildcards.model}_run.py"

rule plot_sir:
    '''Plots the trajectories of the SIR model.

    Input:
        - Numpy Array of SIR trajectories.

    Output:
        - PNG file with an SIR plot.
    '''
    input:
        "{path}/trajectories_sir.npy"
    output:
        "{path}/trajectories_sir.png"
    script:
        "scripts/sir_plot.py"

rule qois_sir:
    '''Calculates the Quantities of Interest of the SIR model.

    The QOIs include total epidemic size, peak of number of infected
    people, and time-to-peak.

    Input:
        - Numpy array of SIR trajectories.

    Output:
        - YAML file with the QOIs of the SIR model.
    '''
    input:
        "{path}/trajectories_sir.npy"
    output:
        "{path}/qois_sir.yaml"
    script:
        "scripts/model_qois_sir.py"

rule draw_original:
    input:
        "data/networks/{graph}/drawing.png"
    output:
        "results/{graph}/drawing.png"
    shell:
        """
        mv {input[0]} {output[0]}
        """

rule gexf:
    '''Generates a gexf file of a graph.

    Stores the graph in the .gexf format compatible with gephi.

    Input:
        - Scipy Sparse Array containing the adjacency matrix of a grpah.

    Output:
        - .gexf file of the graph.
    '''
    input:
        "{path}/graph_adjacency.npz"
    output:
        "{path}/graph.gexf"
    script:
        "scripts/graph_gexf.py"

rule plot_graph:
    '''Creates a visualization of the graph dataset.

    Utilizes the ForceAtlas2 algorithm to generate the layout on the graph
    and draw it on a plane.

    Input:
        - Scipy Sparse Array containing the adjacency matrix of the graph.

    Output:
        - PNG file with a visualization of the graph dataset
    '''
    input:
        "{path}/graph_adjacency.npz"
    output:
        "{path}/drawing.png"
    log:
        "{path}/drawing.log"
    conda:
        "envs/viz.yaml"
    shell:
        """
        python -u scripts/graph_draw.py {input[0]} {output[0]} &> {log}
        """
