import numpy as np
import pandas as pd
import yaml
import shutil

configfile: "config/config_grts.yaml"
wildcard_constraints:
    method="coarsening|sparsification"

def cartesian_product(*arrays):
    meshgrids = np.meshgrid(*arrays,indexing='ij')
    cart_prod = np.stack(meshgrids,axis=-1)
    cart_prod = cart_prod.reshape(-1,len(arrays))
    return cart_prod

def generate_samples(method_config):
    '''Generates the samples for the method
    '''
    samples = cartesian_product(eval(*method_config['parameters'].values()))
    samples = np.tile(samples,(method_config['n_graphs'],1))

    samples = pd.DataFrame(samples,columns=method_config['parameters'].keys())
    samples.rename(lambda idx: f"graph_{idx}", inplace=True)

    return samples

def load_dict(rc_file):
    with open(rc_file,'r') as file:
        return yaml.safe_load(file)

# Retrieve methods to analyze
methods = config['methods'].keys()

# Generate the samples for each method
samples = {method: generate_samples(config['methods'][method]) for method in methods}

rule all:
    input:
        expand("results/giant_hamsterster/{method}/plots/metrics_01.png",method=["sparsification","coarsening"])

rule summarize:
    input:
        files=lambda w:[f"data/networks/{w.graph}/{w.method}/{idx}/{w.file}.yaml" for idx in samples[w.method].index]
    output:
        "results/{graph}/{method}/{file}.csv"
    script:
        "scripts/summarize.py"

rule miniaturization_params:
    input:
        "data/networks/{graph}/metrics.yaml"
    output:
        "data/networks/{graph}/miniaturization/parameters_{id}.yaml"
    resources:
        runtime=120,
        mem_mb=2000
    log:
        "logs/{graph}/reduction/miniaturization/parameters_{id}/parameters.log"
    script:
        "scripts/miniaturization_params.py"

rule miniaturization:
    input:
        "data/networks/{graph}/metrics.yaml",
        "data/networks/{graph}/miniaturization/parameters_{id}.yaml"
    output:
        "data/networks/{graph}/miniaturization/graph_{id}_{idx}/graph_adjacency.npz",
        directory("data/networks/{graph}/miniaturization/graph_{id}_{idx}/trajectories")
    params:
        shrinkage=0.9,
        n_changes=10,
        n_steps=1000,
        n_substeps=50
    resources:
        tasks=6,
        mpi="mpiexec"
    log:
        "logs/{graph}/reduction/miniaturization/parameters_{id}/graph_{idx}_min.log"
    shell:
        """
        {resources.mpi} -n {resources.tasks} scripts/miniaturize.py 
            {input[0]}
            {input[1]}
            {output[0]}
            {output[1]}
            --n_changes {params.n_changes}
            --n_steps {params.n_steps}
            --n_substeps {params.n_substeps}
        """


rule graph_reduce:
    input:
        "data/networks/{graph}/graph_adjacency.npz",
    output:
        "data/networks/{graph}/{method}/{graph_idx}/graph_adjacency.npz",
        "data/networks/{graph}/{method}/{graph_idx}/params_reduction.yaml"
    log:
        "logs/reduction_{graph}/{method}/{graph_idx}.log"
    message:
        "Reducing {wildcards.graph} ({wildcards.graph_idx}) using {wildcards.method}..."
    params:
        method_parameters=lambda w: samples[w.method].loc[w.graph_idx].to_dict()
    resources:
        runtime=120,
        mem_mb=1000
    script:
        "scripts/graph_reduce.py"

rule graph_metrics:
    input:
        "{path}/graph_adjacency.npz"
    output:
        "{path}/graph_metrics.yaml"
    script:
        "scripts/graph_characterize.py"

rule graph_distribution:
    input:
        "{path}/graph_adjacency.npz"
    output:
        "{path}/distribution_{quantity}.npy"
    script:
        "scripts/graph_distribution.py"

rule graph_distribution_metrics:
    input:
        "{path}/distribution_{quantity}.npy"
    output:
        "{path}/distribution_{quantity}.yaml"
    script:
        "scripts/graph_distribution_metrics.py"

rule model_simulate:
    input:
        "{path}/graph_adjacency.npz",
    output:
        "{path}/trajectories_{model}.npy"
    params:
        config=lambda w:config['models'][w.model]
    resources:
        runtime=60,
        mem_mb=1000,
        cpus_per_task=1,
    script:
        "scripts/simulation_{wildcards.model}_run.py"

rule model_plot:
    input:
        "{path}/trajectories_sir.npy"
    output:
        "{path}/trajectories_sir.png"
    script:
        "scripts/sir_plot.py"

rule model_qois_sir:
    input:
        "{path}/trajectories_sir.npy"
    output:
        "{path}/qois_sir.yaml"
    script:
        "scripts/model_qois_sir.py"

rule draw_original:
    input:
        "data/networks/{graph}/drawing.png"
    output:
        "results/{graph}/drawing.png"
    shell:
        """
        mv {input[0]} {output[0]}
        """

rule draw_reductions:
    input:
        files=lambda w: [f"data/networks/{w.graph}/{w.method}/{graph_idx}/drawing.png" for graph_idx in samples[w.method].index]
    output:
        directory("results/{graph}/{method}/drawings/")
    params:
        names=lambda w: samples[w.method].index        
    run:
        os.makedirs(output[0],exist_ok=True)

        # Move files
        for file,name in zip(input.files,params.names):
            shutil.copy(file,os.path.join(output[0],f"{name}.png"))

rule get_gexf:
    input:
        "{path}/graph_adjacency.npz"
    output:
        "{path}/graph.gexf"
    script:
        "scripts/graph_gexf.py"

rule collect_gexf:  
    input:
        files=lambda w: [f"data/networks/{w.graph}/{w.method}/{graph_idx}/graph.gexf" for graph_idx in samples[w.method].index]
    output:
        directory("results/{graph}/{method}/gexf/")
    params:
        names=lambda w: samples[w.method].index
    run:
        os.makedirs(output[0],exist_ok=True)

        for file, name in zip(input.files,params.names):
            shutil.copy(file,os.path.join(output[0],f"{name}.gexf"))

        


# rule plot_graphs:
#     input:
#         original="data/networks/{graph}/drawing.png",
#         reductions=expand("data/networks/{{graph}}/{{method}}/graph_{idx}/drawing.png",idx=[0,1])
#     output:
#         original="results/{graph}/
#         directory("results/{graph}/{method}/graphs/")
#     shell:
#         """
#         mkdir -p   {output[0]}
#         for i in {input}; do
#             cp $i {output[0]}
#         done
#         """

rule plot_reduction:
    input:
        expand("results/{{graph}}/{{method}}/{file}.csv",
            file=["params_reduction",
                  "graph_metrics",
                  "distribution_degree",
                  "distribution_distance",
                  "qois_sir"]),
        metrics="data/networks/{graph}/graph_metrics.yaml",
        d_degree="data/networks/{graph}/distribution_degree.yaml",
        d_distance="data/networks/{graph}/distribution_distance.yaml",
        qois_sir="data/networks/{graph}/qois_sir.yaml"
    output:
        expand("results/{{graph}}/{{method}}/plots/{file}.png",
            file=["metrics_01",
                   "metrics_02",
                   "moments",
                   "sir",
                   "degroot"])
    params:
        rc=load_dict(config['rc_file'])
    notebook:
        "notebooks/analysis_reduction.py.ipynb"

rule graph_draw:
    input:
        "{path}/graph_adjacency.npz"
    output:
        "{path}/drawing.png"
    log:
        "{path}/drawing.log"
    conda:
        "envs/viz.yaml"
    shell:
        """
        python -u scripts/graph_draw.py {input[0]} {output[0]} &> {log}
        """
