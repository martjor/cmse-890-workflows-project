import numpy as np
import pandas as pd
import yaml
import shutil

configfile: "config/config.yaml"

graph = config['graph']
methods = ["miniaturization","coarsening","sparsification"]
miniatures = list(config['miniatures'].keys())

rule all:
    input:
        f"results/{graph}/drawings/giant.png",
        expand("results/{graph}/drawings/{method}/{miniature}.png",
            graph=graph,
            method=methods,
            miniature=miniatures),
        expand("results/{graph}/sir/{which}_{method}.png",
            graph=graph,
            which=["trajectories","qois"],
            method=methods),
        expand("results/{graph}/metrics/{which}_{method}.png",
            graph=graph,
            which=["spectral","reduction","networks"],
            method=methods),
        expand("results/{graph}/miniaturization/trajectories_{which}_{miniature}.png",
            graph=graph,
            which=["plane","error"],
            miniature=miniatures)

def miniaturization_params_params(wildcards):
    # Configuration for the current miniature
    config_min = config['miniatures'][wildcards.miniature]
    params = {'alpha': config_min['alpha'],
              'n_changes': config_min['n_changes'],
              'n_trials': config_min['params']['n_trials'],
              'n_steps': config_min['params']['n_steps']
    }

    return params

rule miniaturization_params:
    '''Calculates the optimal miniaturization parameters of a graph
    
    Input:
        - YAML file containing the metrics of the graphs to miniaturize

    Output:
        - YAML file containg the optimal weights and inverse temperature to miniaturize
          the graph to the specified size
    '''
    input:
        "data/networks/{graph}/giant/metrics.yaml"
    output:
        "data/networks/{graph}/giant/miniaturization/{miniature}/weights.yaml"
    resources:
        runtime=400,
        mem_mb=2000
    log:
        "logs/{graph}/miniaturization/{miniature}/reduction_weights.log"
    params:
        miniaturization_params_params
    script:
        "scripts/reduction/miniaturize_params.py"

rule miniaturization:
    '''Miniaturizes a graph using the parallel tempering algorithm

    Input:
        - YAML file containing the of the graph
        - YAML file containing the miniaturization weights and inverse temperature
    
    Output:
        - Scipy Sparse Array representing the adjacency matrix of the miniature
        - Directory of parquet files containing the individual trajectories of each
          replica of the parallel tempering algorithm
    '''
    input:
        "data/networks/{graph}/giant/metrics.yaml",
        "data/networks/{graph}/giant/miniaturization/{miniature}/weights.yaml"
    output:
        "data/networks/{graph}/giant/miniaturization/{miniature}/graph_adjacency.npz",
        directory("data/networks/{graph}/giant/miniaturization/{miniature}/trajectories")
    params:
        lambda w: config['miniatures'][w.miniature]
    resources:
        runtime=1440,
        mem_mb=6000,
        tasks=6,
        mpi="mpiexec"
    conda:
        "envs/miniaturize.yaml"
    log:
        "logs/{graph}/miniaturization/{miniature}/reduction.log"
    shell:
        "{resources.mpi} -n {resources.tasks} python -m scripts.reduction.miniaturize"
        " {input[0]} {input[1]} {output[0]} {output[1]} {params[0][alpha]}"
        " --n_changes {params[0][n_changes]}"
        " --n_steps {params[0][pt][n_steps]}"
        " --n_substeps {params[0][pt][n_substeps]}"
        " --log-file {log[0]}"

rule coarsen:
    '''Coarsens a graph dataset

    Input:
        - Scipy Sparse Array containing the adjacency matrix of the graph to coarsen
    
    Output:
        - Scipy Sparse Array containing the adjacency matrix of the reduced graph
    '''
    input:
        "data/networks/{graph}/giant/graph_adjacency.npz",
    output:
        "data/networks/{graph}/giant/coarsening/{miniature}/graph_adjacency.npz",
    log:
        "logs/{graph}/coarsening/{miniature}/reduction.log"
    message:
        "Coarsening graph '{wildcards.graph}' ({wildcards.miniature})..."
    params:
        alpha=lambda w:config['miniatures'][w.miniature]['alpha']
    resources:
        runtime=60,
        mem_mb=2000
    script:
        "scripts/reduction/coarsen.py"

rule sparsify:
    '''Sparsifies a graph dataset

    Input:
        - Scipy Sparse Array with the adjacency matrix the graph to sparsify.
    Output:
        - Scipy Sparse Array with the adjacency matrix of the sparsified graph.
    '''
    input:
        "data/networks/{graph}/giant/graph_adjacency.npz",
        "data/networks/{graph}/giant/miniaturization/{miniature}/graph_metrics.yaml"
    output:
        "data/networks/{graph}/giant/sparsification/{miniature}/graph_adjacency.npz"
    log:
        "logs/{graph}/sparsification/{miniature}/reduction.log"
    message:
        "Sparsifying graph '{wildcards.graph}' ({wildcards.miniature})..."
    resources:
        runtime=15,
        mem_mb=6000
    script:
        "scripts/reduction/sparsify.py"

rule metrics:
    '''Characterizes a graph by calculating its relevant metrics

    Input:
        - Scipy Sparse Array containing the adjacency matrix of the graph
    
    Output:
        - YAML file containing the network metrics of the graph
    '''
    input:
        "{path}/graph_adjacency.npz"
    output:
        "{path}/graph_metrics.yaml"
    script:
        "scripts/graph_characterize.py"

rule distribution:
    '''Calculates the distribution over some node property

    The degree distribution of the pairwise-distance distribution of graph
    nodes is calculated. 

    Input:
        - Scipy Sparse Array containing the adjacency matrix of the graph

    Output:
        - 2-D Numpy Array representing the PDF of the specified property.
          The first column contains that the prroperty takes. The second
          column are the frequencies for each value.
    '''
    input:
        "{path}/graph_adjacency.npz"
    output:
        "{path}/distribution_{quantity}.npy"
    script:
        "scripts/graph_distribution.py"

rule distribution_metrics:
    '''Calculates metrics from the specified distribution. 

    Calculates relevant measures of central tendency as well as some 
    low order moments of the distribution.

    Input:
        - Numpy Array containing the distribution.

    Output:
        - YAML file containing the requested metrics.
    '''
    input:
        "{path}/distribution_{quantity}.npy"
    output:
        "{path}/distribution_{quantity}.yaml"
    script:
        "scripts/graph_distribution_metrics.py"

rule sir:
    '''Simulates the diffusion model on the graph.

    For the SIR model, the trajectories returned by the rule are the 
    normalized populations for each compartment at every iteration.

    Input:
        - Scipy Sparse Array containing the adjacency matrix of the graph.

    Output:
        - Numpy Array containing the relevant trajectories of the model.
    '''
    input:
        "{path}/graph_adjacency.npz",
    output:
        "{path}/sir_trajectories.npy"
    params:
        config=lambda w:config['sir']
    resources:
        runtime=60,
        mem_mb=1000,
        cpus_per_task=1,
    script:
        "scripts/sir/simulate.py"

rule draw_miniaturization:
    '''Generates visualization for PT miniaturization.
    '''
    input:
        "data/networks/{graph}/giant/graph_metrics.yaml",
        "data/networks/{graph}/giant/miniaturization/{miniature}/graph_metrics.yaml",
        "data/networks/{graph}/giant/miniaturization/{miniature}/trajectories"
    output:
        "results/{graph}/miniaturization/trajectories_plane_{miniature}.png",
        "results/{graph}/miniaturization/trajectories_error_{miniature}.png"
    notebook:
        "scripts/draw/miniaturization_trajectories.py.ipynb"

rule draw_metrics:
    '''Plots the evolution of graph metrics.
    '''
    input:
        "data/networks/{graph}/giant/graph_metrics.yaml",
        expand("data/networks/{{graph}}/giant/{{method}}/{miniature}/graph_metrics.yaml",miniature=miniatures)
    params:
        alpha=lambda w: {miniature: config['miniatures'][miniature]['alpha'] for miniature in miniatures}
    output:
        "results/{graph}/metrics/reduction_{method}.png",
        "results/{graph}/metrics/networks_{method}.png",
        "results/{graph}/metrics/spectral_{method}.png"
    notebook:
        "scripts/draw/metrics.py.ipynb"

def draw_sir_input(wildcards):
    # Define extension
    if wildcards.type == "trajectories":
        extension = "npy"
    elif wildcards.type == "qois":
        extension = "yaml"

    # Construct list of input files
    files = []
    files.append(f"data/networks/{wildcards.graph}/giant/sir_{wildcards.type}.{extension}")
    for miniature in miniatures:
        files.append(f"data/networks/{wildcards.graph}/giant/{wildcards.method}/{miniature}/sir_{wildcards.type}.{extension}")

    return files

rule draw_sir:
    '''Plots the trajectories of the SIR model.

    Input:
        - Numpy Array of SIR trajectories.

    Output:
        - PNG file with an SIR plot.
    '''
    input:
        draw_sir_input
    params:
        alpha=lambda w: {miniature: config['miniatures'][miniature]['alpha'] for miniature in miniatures}
    output:
        "results/{graph}/sir/{type}_{method}.png"
    notebook:
        "scripts/draw/sir_{wildcards.type}.py.ipynb"

rule qois_sir:
    '''Calculates the Quantities of Interest of the SIR model.

    The QOIs include total epidemic size, peak of number of infected
    people, and time-to-peak.

    Input:
        - Numpy array of SIR trajectories.

    Output:
        - YAML file with the QOIs of the SIR model.
    '''
    input:
        "{path}/sir_trajectories.npy"
    output:
        "{path}/sir_qois.yaml"
    script:
        "scripts/sir/qois.py"



rule layout:
    '''Calculates the graph layout to enable visualization

    Utilizes the ForceAtlas2 algorithm to calculate the layout of the graph dataset.

    Input:
        - Scipy Sparse Array containing the adjacency matrix of the graph.

    Output:
        - Numpy array containing the positions specifying the graph layout
    '''
    input:
        "{path}/graph_adjacency.npz"
    output:
        "{path}/graph_layout.npy"
    params:
        max_iter=config['viz']['max_iter']
    script:
        "scripts/draw/graph_layout.py"

rule draw_reduction:
    input:
        "data/networks/{graph}/giant/{method}/{miniature}/graph_adjacency.npz",
        "data/networks/{graph}/giant/{method}/{miniature}/graph_layout.npy"
    output:
        "results/{graph}/drawings/{method}/{miniature}.png"
    wildcard_constraints:
        method="coarsening|miniaturization"
    message:
        "Drawing graph {wildcards.miniature} for {wildcards.method}..."
    script:
        "scripts/draw/graph.py"

rule draw_sparsification:
    '''Creates a visualization of the graph dataset.

    Takes a previously generated graph layout and draws a graph on top of it.

    Input:
        - Numpy Array containing the graph layout

    Output:
        - PNG file with a visualization of the graph dataset
    '''
    input:
        "data/networks/{graph}/giant/sparsification/{miniature}/graph_adjacency.npz",
        "data/networks/{graph}/giant/graph_layout.npy"
    output:
        "results/{graph}/drawings/sparsification/{miniature}.png"
    message:
        "Drawing graph {wildcards.miniature} for sparsification..."
    script:
        "scripts/draw/graph.py"

rule draw_graph_original:
    input:
        "data/networks/{graph}/giant/graph_adjacency.npz",
        "data/networks/{graph}/giant/graph_layout.npy"
    output:
        "results/{graph}/drawings/giant.png"
    message:
        "Drawing graph {wildcards.graph}..."
    script:
        "scripts/draw/graph.py"

