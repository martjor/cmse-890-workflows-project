import yaml
import pandas as pd
import peppy
import numpy as np
import sys 
import os
import networkx as nx

configfile: "config/config.yaml"

# Auxilieary Functions
def cartesian_product(*arrays):
    meshgrids = np.meshgrid(*arrays,indexing='ij')
    cart_prod = np.stack(meshgrids,axis=-1)
    cart_prod = cart_prod.reshape(-1,len(arrays))
    return cart_prod

def get_n_graphs(file_name):
    '''Retrives number of metrics from configuration file
    '''
    with open(file_name,'r') as file:
        p = yaml.safe_load(file)

    n_inputs = eval(p['targets']).shape[0]
    n_graphs = p['n_samples']

    return n_inputs * n_graphs 





# Preamble
metrics = config['metrics']
n_graphs = {metric: get_n_graphs(f"config/config_{metric}.yaml") for metric in metrics}

rule all:
    input:
        #[f"results/{metric}/graphs.csv" for metric in metrics],
        #[f"results/{metric}/qois_sir.csv" for metric in metrics]
        "data/density/graphs/graph_0.npz"

rule seed:
    input:
        config_file="config/config_{metric}.yaml"
    output:
        temp("data/{metric}/params.npy")
    run:
        # Open parameter file
        with open(input.config_file,'r') as file:
            conf = yaml.safe_load(file)

        # Generate input parameters
        parameters = np.tile(eval(conf['targets']),conf['n_samples'])

        # Save parameters
        np.save(output[0],parameters)

rule generate_graph:
    input:
        "data/{metric}/params.npy"
    output:
        "data/{metric}/graphs/graph_{index}.npz",
        #temp("data/{metric}/graphs/metrics_{index}.yaml")
    params:
        n_vertices=100
    script:
        "scripts/generate_graph.py"

rule simulate:
    input:
        "data/{metric}/graphs/graph_{index}.npz"
    output:
        "data/{metric}/simulations/{simulation}/runs/run_{index}.npy"
    params:
        gamma=0.1,
        tau=0.1,
        n_steps=1000,
        n_trials=3,
    script:
        "scripts/simulate_{wildcards.simulation}.py"

rule calculate_qois:
    input:
        "data/{metric}/simulations/{simulation}/runs/run_{index}.npy"
    log:
        "logs/qois_{metric}_{simulation}_{index}.log"
    output:
        "data/{metric}/simulations/{simulation}/qois/quantities_{index}.csv"
    script:
        "scripts/qois_{wildcards.simulation}.py"

rule summarize_graphs:
    input:
        metrics=lambda w: [f"data/{w.metric}/graphs/metrics_{index}.yaml" for index in range(n_graphs[w.metric])]
        
    output:
        "results/{metric}/graphs.csv",

    run:
        # Preamble
        n_graphs = len(input.metrics)
        metrics = [{}] * n_graphs
        
        # Load dictionaries
        for i, file_name in enumerate(input.metrics):
            with open(file_name,'r') as file:
                metrics[i] = yaml.safe_load(file)
        
        # Create dataframe of graphs
        graphs_df = pd.DataFrame(metrics)
        graphs_df.set_index('graph',inplace=True)

        # Save dataframes
        graphs_df.to_csv(output[0])
        

rule summarize_simulation:
    input: 
        qois=lambda w: [f"data/{w.metric}/simulations/{w.simulation}/qois/quantities_{index}.csv" for index in range(n_graphs[w.metric])]
    
    output:
        "results/{metric}/qois_{simulation}.csv"

    run:
        # Preamble
        files = sorted(input.qois)
        n_tables = len(files)
        qois = [0] * n_tables
        # Load quantities of interest
        for i, file_name in enumerate(input.qois):
            # Load Hierarchical DataFrame
            qois[i] = pd.read_csv(file_name,index_col=0).stack()

        # Construct qois dataframe
        qois_df = pd.concat(qois,axis=1).T
        qois_df.rename(lambda idx: f"graph_{idx}.npz",inplace=True)

        # Save dataframe
        qois_df.to_csv(output[0])






    




        